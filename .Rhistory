install.packages("kernlab")
library(kernlab)
data("spam")
set.seed(3435)
trainIndicator = rbinom(4601, sisize = 1, prob = 0.5)
table(trainIndicator)
trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
set.seed(3435)
trainIndicator = rbinom(4601, sisize = 1, prob = 0.5)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)
trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
names(trainSpam)
head(trainSpam)
table(trainSpam$type)
plot(trainSpam$capitalAve ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam[, 1:4] + 1))
hCluster = hclust(dist(t(trainSpam[, 1:57])))
plot(hCluster)
hClusterUD = hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUD)
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum (x ! = (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
costFunction = function(x, y) sum (x! = (y > 0.5))
costFunction = function(x, y) sum (x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
names(trainSpam)[which.min(cvError)]
predictionModel = glm(numType ~charDollar, family = "binomial", data = trainSpam)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.5] = "spam"
table(predictedSpam, testSpam$type)
(61 + 458)/(1346 + 458 + 61 + 449)
?glm
## setwd("~/") - set working directory to folder with the 'UCI HAR Dataset'
## The reshape2 package is needed to run the melt and dcast commands
library (reshape2)
## 1.Merges the training and the test sets to create one data set
## Read the training data, labels & subjects into R
trainingdata <- read.table("~/UCI HAR Dataset/train/X_train.txt")
traininglabels <- read.table("~/UCI HAR Dataset/train/y_train.txt")
trainingsubject <- read.table("~/UCI HAR Dataset/train/subject_train.txt")
## Read the testing data, labels & subject into R
testdata <- read.table("~/UCI HAR Dataset/test/X_test.txt")
testlabels <- read.table("~/UCI HAR Dataset/test/y_test.txt")
testsubject <- read.table("~/UCI HAR Dataset/test/subject_test.txt")
## Read the feature and the acitivity data into R
featuredata <- read.table("~/UCI HAR Dataset/features.txt")
activitydata <- read.table("~/UCI HAR Dataset/activity_labels.txt")
## 2.Extracts only the measurements on the mean and standard deviation for each
## measurement.
## Select mean and standard deviation methods using grep
selectedfeatures <- grep("mean\\(|std\\(", featuredata$V2)
## 3.Uses descriptive activity names to name the activities in the data set
## Change activity name letters into lower case and remove underscores ('_')
activitydata$V2 <- tolower(gsub("_","",activitydata$V2))
## Merge the test and training activities with the descriptive activity labels
mergelabels <- rbind(traininglabels, testlabels)
mergelabels[, 1] <- activitydata[mergelabels[, 1], 2]
names(mergelabels) <- "Activity"
## 4.Labels the data set with descriptive variable names
## Merges the test and training data into together and subsets it with only the
## extracted mean and standard deviation measurements
## Labels the variables using the feature names
mergedata <- rbind(trainingdata, testdata)
mergedata <- mergedata[, selectedfeatures]
names(mergedata) <- featuredata[selectedfeatures, "V2"]
## Change abbreviations in variables into their full form and capitalize the
## starting letters, remove the hyphens and brackets from the variable names
names(mergedata) <- gsub("Acc","Acceleration", names(mergedata))
names(mergedata) <- gsub("Mag","Magnitude", names(mergedata))
names(mergedata) <- gsub("Freq","Frequency", names(mergedata))
names(mergedata) <- gsub("\\-","", names(mergedata))
names(mergedata) <- gsub("std","StandardDeviation",
names(mergedata))
names(mergedata) <- gsub("mean","Mean",
names(mergedata))
names(mergedata) <- gsub("\\(|\\)","", names(mergedata))
## Join training and test subject data sets
## Rename the column name of the combined subject set as "Subject"
mergesubject <- rbind(trainingsubject, testsubject)
names(mergesubject) <- "Subject"
## Bind all three merged data sets into a single tidy data set
tidydata <- cbind(mergesubject,mergelabels,mergedata)
## 5.From the data set in step 4, creates a second, independent tidy data
## set with the average of each variable for each activity and each subject
## Using 'melt' and 'dcast' from the"reshape2" package, create a tidy data set
## with mean values of each variable for all subject and activity combinations
meltvariable <- melt(tidydata, id.vars = c("Subject","Activity"))
tidymeandata <- dcast(meltvariable, Subject+Activity ~ variable, mean)
write.table(tidymeandata, "tidymeandata.txt", row.name = FALSE)
View(tidydata)
View(meltvariable)
View(tidymeandata)
?melt
View(trainingdata)
View(testdata)
Here's an unordered list:
* first thing
* second thing
)
}
´´´
q()
Q
ffff
.
+
8
1!
setwd("U:/RepData_PeerAssessment1")
setwd("U:/RepData_PeerAssessment1")
unzip("activity.zip")
activity_data <- read.csv("activity.csv", sep=",",
header=TRUE,na.strings="NA")
setwd("U:/RepData_PeerAssessment1")
unzip("activity.zip")
activity_data <- read.csv("activity.csv", sep=",",
header=TRUE,na.strings="NA")
activity_data$date <- as.Date(activity_data$date, "%Y-%m-%d")
total_steps <- aggregate(steps ~ date, data = activity_data, sum, na.rm=TRUE)
#PLOT1
hist(total_steps$steps, main = "Total number of steps taken per day",
xlab = "Total Steps", col = "violetred")
## hist(total_steps$steps, breaks=seq(from=0, to=25000, by=2500), main = "Total number of steps taken per day", xlab = "Total Steps",ylim=c(0, 20), col = "violetred")
# sum_data <- aggregate(activity$steps, by=list(activity$date), FUN=sum, na.rm=TRUE)
# names(sum_data) <- c("date", "total")
options(digits = 2)
stepmean <- mean(total_steps$steps)
stepmean
stepmedian <- median(total_steps$steps)
stepmedian
# mean_data <- aggregate(activity$steps, by=list(activity$interval), FUN=mean, na.rm=TRUE)
# PLOT2
interval_steps <- aggregate(steps ~ interval, data = activity_data, mean)
head(interval_steps)
plot(interval_steps$interval, interval_steps$steps, type = "l",
main = "Average number of steps taken per 5-minute intervals of each day",
ylab = "Number of Steps",xlab = "Interval", col = "blue4", lty = 1) #add main, ylab and xlab
maxposition <- which.max(interval_steps$steps)
maxinterval <- interval_steps[maxposition, 1]
maxinterval
#which.max(interval_steps$steps)
#[1] 104
#interval_steps$steps[104]
#[1] 206.1698
NAs <- length(which(is.na(activity_data$steps)))
#Number of missing values: `r NAs`
# PLOT3
NAcount <- sum(is.na(activity_data$steps)) #2304
NApositions <- which(is.na(activity_data$steps))
# Create new data frame with mean values for each interval
withNAs <- merge(activity_data, interval_steps, by = "interval")
NAs <- is.na(withNAs$steps.x)
withNAs$steps.x[NAs] <- withNAs$steps.y[NAs]
withNAs <- withNAs[,1:3]
withNAs <- withNAs[,c(2,3,1)]
names(withNAs) <- c("steps","date","interval")
stepswithNAs <- aggregate(steps ~ date, data = withNAs, sum)
hist(stepswithNAs$steps, main = "Total number of steps taken per day (NAs filled)",
xlab = "Total Steps", col = "violetred")
mean(stepswithNAs$steps)
median(stepswithNAs$steps)
#weekvariable <- function(date){
#       if(weekdays(as.Date(date)) %in% c("Saturday", "Sunday")){
#                day <- "Weekend"
#        }else{
#                day <- "Weekday"
#        }
#}
Sys.setlocale("LC_TIME", locale = "English")
weekdaydata <- withNAs
day <- weekdays(weekdaydata$date) #"Monday","Friday".. etc.
daytype <- ifelse(day == "Saturday" | day == "Sunday",
"Weekend", "Weekday")
daytype <- as.factor(daytype)
weekdaydata$date <- daytype
#plot(interval_steps$interval, interval_steps$stceps, type = "l",
#     col = "blue4", lty = 1) #add main, ylab and xlab
#?chartr
par(mfrow=c(2,1))
mean_steps <- aggregate(steps ~ interval + daytype, data = weekdaydata, mean)
#names(mean_steps) <- c("interval","day_type", "steps_avg")
library(lattice)
xyplot(steps~interval|daytype, mean_steps, type="l", layout = c(1,2),
xlab = "Interval", ylab = "Steps",
main = "Weekend and Weekday Acitivity Patterns")
##  knit2html("FirstKnit.Rmd")
?kint2html
?chartr
weekdaydata$date <- daytype
```
